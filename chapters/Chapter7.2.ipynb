{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 7.2 - Spark Streaming\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "What are you most looking forward to this holiday break?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Annotated Example: WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The usual SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "initialStateRDD = sc.parallelize([(u'hello', 1), (u'world', 1)]) # We'll use this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grab a streaming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After a context is defined:\n",
    "* Define the input sources by creating input DStreams.\n",
    "* Define the streaming computations by applying transformation and output operations to DStreams.\n",
    "* Start receiving data and processing it using streamingContext.start().\n",
    "* Wait for the processing to be stopped (manually or due to any error) using streamingContext.awaitTermination().\n",
    "* The processing can be manually stopped using streamingContext.stop()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points to remember:\n",
    "* Once a context has been started, no new streaming computations can be set up or added to it.\n",
    "* Once a context has been stopped, it cannot be restarted.\n",
    "* Only one StreamingContext can be active in a JVM at the same time.\n",
    "* A SparkContext can be re-used to create multiple StreamingContexts, as long as the previous StreamingContext is stopped (without stopping the SparkContext) before the next StreamingContext is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PORT=9999 # Change this to a unique port before running individually\n",
    "HOST=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this command at the terminal and type in words and hit enter periodically:\n",
      "nc -lk 9999\n"
     ]
    }
   ],
   "source": [
    "print(\"Run this command at the terminal and type in words and hit enter periodically:\")\n",
    "print(f\"nc -lk {PORT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretized Streams (DStreams)\n",
    "* DStream is the basic abstraction provided by Spark Streaming\n",
    "* Continuous stream of data, either the input data stream received from source, or the processed data stream generated by transforming the input stream. \n",
    "* Internally, a DStream is represented by a continuous series of RDDs\n",
    "* Each RDD in a DStream contains data from a certain interval, as shown in the following figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-dstream.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any operation applied on a DStream translates to operations on the underlying RDDs. \n",
    "* In our example of converting a stream of lines to words, the flatMap operation is applied on each RDD in the lines DStream to generate the RDDs of the words DStream. \n",
    "* This is shown in the following figure:\n",
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-dstream-ops.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:41\n",
      "-------------------------------------------\n",
      "('', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:42\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:43\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:44\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:45\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:46\n",
      "-------------------------------------------\n",
      "('testing', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:47\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:48\n",
      "-------------------------------------------\n",
      "('test', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:49\n",
      "-------------------------------------------\n",
      "('testing', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:33:50\n",
      "-------------------------------------------\n",
      "('blah', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = ssc.socketTextStream(HOST, PORT)\n",
    "counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "              .map(lambda word: (word, 1))\\\n",
    "              .reduceByKey(lambda a, b: a+b)\n",
    "counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(10)\n",
    "#ssc.awaitTerminationOrTimeout(60) # wait 60 seconds\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop and think:** What is missing in our previous example? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing is a lack of state. We process the lines in an RDD/DStream and print the results. What if we wanted to accumulate the word counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:50\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:51\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:52\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:53\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:54\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:41:55\n",
      "-------------------------------------------\n",
      "('hello', 1)\n",
      "('world', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc = StreamingContext(sc, 1)\n",
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "# RDD with initial state (key, value) pairs\n",
    "\n",
    "def updateFunc(new_values, last_sum):\n",
    "    return sum(new_values) + (last_sum or 0)\n",
    "\n",
    "lines = ssc.socketTextStream(HOST,PORT)\n",
    "running_counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "                      .map(lambda word: (word, 1))\\\n",
    "                      .updateStateByKey(updateFunc, initialRDD=initialStateRDD)\n",
    "\n",
    "running_counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(5)\n",
    "#ssc.awaitTerminationOrTimeout(60) # wait 60 seconds\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring a directory\n",
    "\n",
    "You can monitor a directory and apply the same processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:09\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:10\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:11\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:12\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:13\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:14\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:15\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:16\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:17\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:18\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:19\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:20\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:21\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:22\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:23\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:24\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:25\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:26\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:27\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:28\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:29\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:30\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:31\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:32\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:33\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:34\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:35\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:36\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:37\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-11-03 10:46:38\n",
      "-------------------------------------------\n",
      "('', 3113)\n",
      "('EBook', 1)\n",
      "('of', 1343)\n",
      "('Affair', 5)\n",
      "('other', 58)\n",
      "('are', 183)\n",
      "('check', 3)\n",
      "('where', 47)\n",
      "('using', 5)\n",
      "('Styles', 26)\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/tmp/add_books_here\"\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "# RDD with initial state (key, value) pairs\n",
    "\n",
    "def updateFunc(new_values, last_sum):\n",
    "    return sum(new_values) + (last_sum or 0)\n",
    "\n",
    "lines = ssc.textFileStream(data_dir)\n",
    "\n",
    "running_counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "                      .map(lambda word: (word, 1))\\\n",
    "                      .updateStateByKey(updateFunc)\n",
    "\n",
    "running_counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(30)\n",
    "#ssc.awaitTerminationOrTimeout(60) # wait 60 seconds\n",
    "ssc.stop(stopSparkContext=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridging Streaming and Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2021-11-03 10:59:49 =========\n",
      "========= 2021-11-03 10:59:50 =========\n",
      "========= 2021-11-03 10:59:51 =========\n",
      "========= 2021-11-03 10:59:52 =========\n",
      "========= 2021-11-03 10:59:53 =========\n",
      "========= 2021-11-03 10:59:54 =========\n",
      "========= 2021-11-03 10:59:55 =========\n",
      "========= 2021-11-03 10:59:56 =========\n",
      "========= 2021-11-03 10:59:57 =========\n",
      "========= 2021-11-03 10:59:58 =========\n",
      "========= 2021-11-03 10:59:59 =========\n",
      "========= 2021-11-03 11:00:00 =========\n",
      "========= 2021-11-03 11:00:01 =========\n",
      "+------------+-----+\n",
      "|        word|total|\n",
      "+------------+-----+\n",
      "|      online|   12|\n",
      "|          By|   95|\n",
      "|   emotions.|    5|\n",
      "|        some| 1472|\n",
      "|      Volume|    3|\n",
      "|       still|  432|\n",
      "|   connected|   26|\n",
      "|       turn,|   16|\n",
      "|        ‘and|  172|\n",
      "|         few|  225|\n",
      "|        hope|  208|\n",
      "|   solemnity|    6|\n",
      "|       those|  863|\n",
      "|     speak?’|    1|\n",
      "|    suppose;|    3|\n",
      "|    wanders,|    1|\n",
      "|      doubts|   20|\n",
      "|       inner|    3|\n",
      "|cross-barred|    1|\n",
      "|         fog|    4|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "========= 2021-11-03 11:00:02 =========\n",
      "========= 2021-11-03 11:00:03 =========\n",
      "========= 2021-11-03 11:00:04 =========\n",
      "========= 2021-11-03 11:00:05 =========\n",
      "========= 2021-11-03 11:00:06 =========\n",
      "========= 2021-11-03 11:00:07 =========\n",
      "========= 2021-11-03 11:00:08 =========\n",
      "========= 2021-11-03 11:00:09 =========\n",
      "========= 2021-11-03 11:00:10 =========\n",
      "========= 2021-11-03 11:00:11 =========\n",
      "========= 2021-11-03 11:00:12 =========\n",
      "========= 2021-11-03 11:00:13 =========\n",
      "========= 2021-11-03 11:00:14 =========\n",
      "========= 2021-11-03 11:00:15 =========\n",
      "========= 2021-11-03 11:00:16 =========\n",
      "========= 2021-11-03 11:00:17 =========\n",
      "========= 2021-11-03 11:00:18 =========\n",
      "========= 2021-11-03 11:00:19 =========\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/tmp/add_books_here\"\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import traceback\n",
    "\n",
    "# Lazily instantiated global instance of SparkSession\n",
    "def getSparkSessionInstance(sparkConf):\n",
    "    if (\"sparkSessionSingletonInstance\" not in globals()):\n",
    "        globals()[\"sparkSessionSingletonInstance\"] = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(conf=sparkConf) \\\n",
    "            .getOrCreate()\n",
    "    return globals()[\"sparkSessionSingletonInstance\"]\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "lines = ssc.textFileStream(data_dir)\n",
    "\n",
    "def process(time, rdd):\n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    # Get the singleton instance of SparkSession\n",
    "    try:\n",
    "        spark = getSparkSessionInstance(rdd.context.getConf())\n",
    "        # Convert RDD[String] to RDD[Row] to DataFrame\n",
    "        words = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: word)\n",
    "        rowRdd = words.map(lambda w: Row(word=w))\n",
    "        wordsDataFrame = spark.createDataFrame(rowRdd)\n",
    "\n",
    "        # Creates a temporary view using the DataFrame\n",
    "        wordsDataFrame.createOrReplaceTempView(\"words\")\n",
    "\n",
    "        # Do word count on table using SQL and print it\n",
    "        wordCountsDataFrame = spark.sql(\"select word, count(*) as total from words group by word\")\n",
    "        print(wordCountsDataFrame.show())\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "lines.foreachRDD(process)\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(30)\n",
    "#ssc.awaitTerminationOrTimeout(60) # wait 60 seconds\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
