{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 6 - Spark SQL\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "Good rainy day story or snow day story?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While this text can be viewed as PDF, it is most useful to have a Jupyter environment. I have an environment ready for each of you, but you can get your own local environment going in several ways. One popular way is with Anaconda (<a href=\"https://www.anaconda.com/\">https://www.anaconda.com/</a>. Because of the limited time, you can use my server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spark SQL\n",
    "* Designed for structured data\n",
    "* Seamlessly mix SQL queries with Spark programs\n",
    "* Connects to many difference datasources: Hive, Avro, Parquet, ORC, JSON, and JDBC.\n",
    "* You can join across datasources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## JSON\n",
    "* JSON stands for JavaScript Object Notation\n",
    "* JSON is simply a way of representing data independent of a platform\n",
    "* An alternative to JSON is XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XML vs JSON\n",
    "* Both are human-readable and machine-readable\n",
    "* Most people would agree that JSON is easier to read\n",
    "* JSON is faster for computers to process\n",
    "* Both contain actual data and meta-information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why are we talking about JSON? I thought this was Spark SQL\n",
    "* Spark SQL is all about structured data\n",
    "* We will therefore need to talk about different ways to represent structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example JSON file\n",
    "<img src=\"https://static.goanywhere.com/images/tutorials/read-json/ExampleJSON2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### JSON Syntax\n",
    "* Collection of attribute/value pairs enclosed by curly brackets.\n",
    "* The attribute is just the name of the attribute surrounded by double quotes (double and not single)\n",
    "* The value can be:\n",
    "    * a string (in double quotes), \n",
    "    * a number,  \n",
    "    * a list of *things* of the same type (in square brackets). \n",
    "* The *thing* can be a string, a number, or a JSON expression.\n",
    "* : is put between the attribute and the value and the different attribute/value pairs are separated by comma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## JSON to Python\n",
    "<img src=\"https://miro.medium.com/max/1484/1*uMSJMK2XLpDBfPABFZ9kTg.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back into Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Examine: <a href=\"https://corgis-edu.github.io/corgis/json/covid/\">https://corgis-edu.github.io/corgis/json/covid/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "home = str(Path.home())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement of Spark is that JSON is flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(open(f\"{home}/csc-369-student/data/corgis/datasets/json/covid/covid.json\").read())\n",
    "open(f\"{home}/csc-369-student/data/corgis/datasets/json/covid/covid_flat.json\",\"w\").write(json.dumps(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|                Data|          Date|            Location|\n",
      "+--------------------+--------------+--------------------+\n",
      "|[121, 6, 38041757...| [5, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[86, 4, 38041757,...| [4, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[95, 3, 38041757,...| [3, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[132, 5, 38041757...| [2, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[76, 0, 38041757,...| [1, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[157, 4, 38041757...|[31, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[123, 3, 38041757...|[30, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[0, 0, 38041757, ...|[29, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[113, 7, 38041757...|[28, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[199, 8, 38041757...|[27, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[65, 3, 38041757,...|[26, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[81, 4, 38041757,...|[25, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[61, 2, 38041757,...|[24, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[116, 4, 38041757...|[23, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[135, 2, 38041757...|[22, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[88, 2, 38041757,...|[21, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[87, 5, 38041757,...|[20, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[59, 4, 38041757,...|[19, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[68, 3, 38041757,...|[18, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[47, 4, 38041757,...|[17, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark is an existing SparkSession\n",
    "df = spark.read.json(f\"{home}/csc-369-student/data/corgis/datasets/json/covid/covid_flat.json\")\n",
    "# Displays the content of the DataFrame to stdout\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Print the schema in a tree format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Data: struct (nullable = true)\n",
      " |    |-- Cases: long (nullable = true)\n",
      " |    |-- Deaths: long (nullable = true)\n",
      " |    |-- Population: long (nullable = true)\n",
      " |    |-- Rate: double (nullable = true)\n",
      " |-- Date: struct (nullable = true)\n",
      " |    |-- Day: long (nullable = true)\n",
      " |    |-- Month: long (nullable = true)\n",
      " |    |-- Year: long (nullable = true)\n",
      " |-- Location: struct (nullable = true)\n",
      " |    |-- Code: string (nullable = true)\n",
      " |    |-- Continent: string (nullable = true)\n",
      " |    |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How do we grab a single column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Location|\n",
      "+--------------------+\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "|[AFG, Asia, Afgha...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Location\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Day|\n",
      "+---+\n",
      "|  5|\n",
      "|  4|\n",
      "|  3|\n",
      "|  2|\n",
      "|  1|\n",
      "| 31|\n",
      "| 30|\n",
      "| 29|\n",
      "| 28|\n",
      "| 27|\n",
      "| 26|\n",
      "| 25|\n",
      "| 24|\n",
      "| 23|\n",
      "| 22|\n",
      "| 21|\n",
      "| 20|\n",
      "| 19|\n",
      "| 18|\n",
      "| 17|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Date.Day\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|                Data|          Date|            Location|\n",
      "+--------------------+--------------+--------------------+\n",
      "|[157, 4, 38041757...|[31, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[123, 3, 38041757...|[30, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[0, 0, 38041757, ...|[29, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[113, 7, 38041757...|[28, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[199, 8, 38041757...|[27, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[65, 3, 38041757,...|[26, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[81, 4, 38041757,...|[25, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[61, 2, 38041757,...|[24, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[116, 4, 38041757...|[23, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[135, 2, 38041757...|[22, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[15, 2, 38041757,...| [30, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[12, 3, 38041757,...| [29, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[0, 0, 38041757, ...| [28, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[35, 0, 38041757,...| [27, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[6, 2, 38041757, ...| [26, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[16, 0, 38041757,...| [25, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[25, 5, 38041757,...| [24, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[71, 2, 38041757,...| [23, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[30, 3, 38041757,...| [22, 9, 2020]|[AFG, Asia, Afgha...|\n",
      "|[19, 0, 38041757,...| [31, 8, 2020]|[AFG, Asia, Afgha...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Date.Day'] > 21).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Country|count|\n",
      "+--------------------+-----+\n",
      "|                Chad|  231|\n",
      "|            Anguilla|  224|\n",
      "|            Paraguay|  239|\n",
      "|              Russia|  311|\n",
      "|               Yemen|  210|\n",
      "|        Burkina_Faso|  238|\n",
      "|Cases_on_an_inter...|   64|\n",
      "|             Senegal|  241|\n",
      "|              Sweden|  311|\n",
      "|         Timor_Leste|  229|\n",
      "|    Marshall_Islands|    8|\n",
      "|              Guyana|  236|\n",
      "|             Eritrea|  229|\n",
      "|              Jersey|  231|\n",
      "|         Philippines|  307|\n",
      "|            Djibouti|  232|\n",
      "|            Malaysia|  310|\n",
      "|        Sierra_Leone|  219|\n",
      "|           Singapore|  311|\n",
      "|        South_Africa|  243|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Location.Country\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But what happened to the SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|                Data|          Date|            Location|\n",
      "+--------------------+--------------+--------------------+\n",
      "|[121, 6, 38041757...| [5, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[86, 4, 38041757,...| [4, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[95, 3, 38041757,...| [3, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[132, 5, 38041757...| [2, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[76, 0, 38041757,...| [1, 11, 2020]|[AFG, Asia, Afgha...|\n",
      "|[157, 4, 38041757...|[31, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[123, 3, 38041757...|[30, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[0, 0, 38041757, ...|[29, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[113, 7, 38041757...|[28, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[199, 8, 38041757...|[27, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[65, 3, 38041757,...|[26, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[81, 4, 38041757,...|[25, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[61, 2, 38041757,...|[24, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[116, 4, 38041757...|[23, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[135, 2, 38041757...|[22, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[88, 2, 38041757,...|[21, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[87, 5, 38041757,...|[20, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[59, 4, 38041757,...|[19, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[68, 3, 38041757,...|[18, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "|[47, 4, 38041757,...|[17, 10, 2020]|[AFG, Asia, Afgha...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"covid\") # create a temporary view so we can query our data\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT * FROM covid\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A lot to examine\n",
    "\n",
    "### Returns dataframe column names and data types\n",
    "df.dtypes\n",
    "### Displays the content of dataframe\n",
    "df.show()\n",
    "### Return first n rows\n",
    "df.head()\n",
    "### Returns first row\n",
    "df.first()\n",
    "### Return first n rows\n",
    "df.take(5)\n",
    "### Computes summary statistics\n",
    "df.describe().show()\n",
    "### Returns columns of dataframe\n",
    "df.columns\n",
    "### Counts the number of rows in dataframe\n",
    "df.count()\n",
    "### Counts the number of distinct rows in dataframe\n",
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Data=Row(Cases=121, Deaths=6, Population=38041757, Rate=3.74588377), Date=Row(Day=5, Month=11, Year=2020), Location=Row(Code='AFG', Continent='Asia', Country='Afghanistan')),\n",
       " Row(Data=Row(Cases=86, Deaths=4, Population=38041757, Rate=3.78268543), Date=Row(Day=4, Month=11, Year=2020), Location=Row(Code='AFG', Continent='Asia', Country='Afghanistan')),\n",
       " Row(Data=Row(Cases=95, Deaths=3, Population=38041757, Rate=3.78794281), Date=Row(Day=3, Month=11, Year=2020), Location=Row(Code='AFG', Continent='Asia', Country='Afghanistan')),\n",
       " Row(Data=Row(Cases=132, Deaths=5, Population=38041757, Rate=3.76691329), Date=Row(Day=2, Month=11, Year=2020), Location=Row(Code='AFG', Continent='Asia', Country='Afghanistan')),\n",
       " Row(Data=Row(Cases=76, Deaths=0, Population=38041757, Rate=3.57501889), Date=Row(Day=1, Month=11, Year=2020), Location=Row(Code='AFG', Continent='Asia', Country='Afghanistan'))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convert to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(121, 6, 38041757, 3.74588377)</td>\n",
       "      <td>(5, 11, 2020)</td>\n",
       "      <td>(AFG, Asia, Afghanistan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(86, 4, 38041757, 3.78268543)</td>\n",
       "      <td>(4, 11, 2020)</td>\n",
       "      <td>(AFG, Asia, Afghanistan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(95, 3, 38041757, 3.78794281)</td>\n",
       "      <td>(3, 11, 2020)</td>\n",
       "      <td>(AFG, Asia, Afghanistan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(132, 5, 38041757, 3.76691329)</td>\n",
       "      <td>(2, 11, 2020)</td>\n",
       "      <td>(AFG, Asia, Afghanistan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(76, 0, 38041757, 3.57501889)</td>\n",
       "      <td>(1, 11, 2020)</td>\n",
       "      <td>(AFG, Asia, Afghanistan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53585</th>\n",
       "      <td>(0, 0, 14645473, 0.0)</td>\n",
       "      <td>(25, 3, 2020)</td>\n",
       "      <td>(ZWE, Africa, Zimbabwe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53586</th>\n",
       "      <td>(0, 1, 14645473, 0.0)</td>\n",
       "      <td>(24, 3, 2020)</td>\n",
       "      <td>(ZWE, Africa, Zimbabwe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53587</th>\n",
       "      <td>(0, 0, 14645473, 0.0)</td>\n",
       "      <td>(23, 3, 2020)</td>\n",
       "      <td>(ZWE, Africa, Zimbabwe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53588</th>\n",
       "      <td>(1, 0, 14645473, 0.0)</td>\n",
       "      <td>(22, 3, 2020)</td>\n",
       "      <td>(ZWE, Africa, Zimbabwe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53589</th>\n",
       "      <td>(1, 0, 14645473, 0.0)</td>\n",
       "      <td>(21, 3, 2020)</td>\n",
       "      <td>(ZWE, Africa, Zimbabwe)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53590 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Data           Date                  Location\n",
       "0      (121, 6, 38041757, 3.74588377)  (5, 11, 2020)  (AFG, Asia, Afghanistan)\n",
       "1       (86, 4, 38041757, 3.78268543)  (4, 11, 2020)  (AFG, Asia, Afghanistan)\n",
       "2       (95, 3, 38041757, 3.78794281)  (3, 11, 2020)  (AFG, Asia, Afghanistan)\n",
       "3      (132, 5, 38041757, 3.76691329)  (2, 11, 2020)  (AFG, Asia, Afghanistan)\n",
       "4       (76, 0, 38041757, 3.57501889)  (1, 11, 2020)  (AFG, Asia, Afghanistan)\n",
       "...                               ...            ...                       ...\n",
       "53585           (0, 0, 14645473, 0.0)  (25, 3, 2020)   (ZWE, Africa, Zimbabwe)\n",
       "53586           (0, 1, 14645473, 0.0)  (24, 3, 2020)   (ZWE, Africa, Zimbabwe)\n",
       "53587           (0, 0, 14645473, 0.0)  (23, 3, 2020)   (ZWE, Africa, Zimbabwe)\n",
       "53588           (1, 0, 14645473, 0.0)  (22, 3, 2020)   (ZWE, Africa, Zimbabwe)\n",
       "53589           (1, 0, 14645473, 0.0)  (21, 3, 2020)   (ZWE, Africa, Zimbabwe)\n",
       "\n",
       "[53590 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parquet\n",
    "* Column oriented data format where data are stored by column rather than by row.\n",
    "* Most expensive operations on hard disks are seeks\n",
    "* Related data should be stored in a fashion to minimize seeks\n",
    "* Many data driven tasks don't need all the columns of a row, but they do need all the data for a subset of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example of row-oriented:\n",
    "<pre>\n",
    "001:10,Smith,Joe,60000;\n",
    "002:12,Jones,Mary,80000;\n",
    "003:11,Johnson,Cathy,94000;\n",
    "004:22,Jones,Bob,55000;</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example of column-oriented\n",
    "<pre>\n",
    "10:001,12:002,11:003,22:004;\n",
    "Smith:001,Jones:002,Johnson:003,Jones:004;\n",
    "Joe:001,Mary:002,Cathy:003,Bob:004;\n",
    "60000:001,80000:002,94000:003,55000:004;</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## And it is as easy as this to work with them in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# DataFrames can be saved as Parquet files, maintaining the schema information.\n",
    "df.write.parquet(\"/tmp/covid.parquet2\")\n",
    "\n",
    "# Read in the Parquet file created above.\n",
    "# Parquet files are self-describing so the schema is preserved.\n",
    "# The result of loading a parquet file is also a DataFrame.\n",
    "parquetFile = spark.read.parquet(\"/tmp/covid.parquet2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|    Country|\n",
      "+-----------+\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "|Afghanistan|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquetFile.select('Location.Country').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wrap-up\n",
    "In addition to the Spark Core API, Spark provides convienent and flexible mechanisms to access structured data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
