{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 7.1 - Spark Streaming\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "What was the best halloween costume you saw over the weekend?\n",
    "\n",
    "Also, what's the best candy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Streaming and Data Analysis\n",
    "Analyzing data as it comes in at a high velocity in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://opensistemas.com/wp-content/uploads/2020/06/4-Vs-of-big-data-1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Velocity\n",
    "\n",
    "* Data drivers\n",
    "    * Social media (e.g., Twitter)\n",
    "    * IoT (e.g., Smart Watches)\n",
    "    * Mobile applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Business Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Streaming ETL\n",
    "* Traditional ETL (Extract, Transform, Load) tools used for batch processing in data warehouse environments must read data, convert it to a database compatible format, and then write it to the target database\n",
    "* With Streaming ETL, data is continually cleaned and aggregated before it is pushed into data stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Enrichment\n",
    "* Enriches live data by combining it with static data, thus allowing organizations to conduct more complete real-time data analysis.\n",
    "* e.g., Online advertisers use data enrichment to combine historical customer data with live customer behavior data and deliver more personalized and targeted ads in real-time and in context with what customers are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trigger Event Detection\n",
    "* Detect and respond quickly to rare or unusual behaviors (“trigger events”) that could indicate a potentially serious problem within the system. \n",
    "* Financial institutions use triggers to detect fraudulent transactions and stop fraud in their tracks. * Hospitals also use triggers to detect potentially dangerous health changes while monitoring patient vital signs—sending automatic alerts to the right caregivers who can then take immediate and appropriate action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Complex Session Analysis\n",
    "* Events relating to live sessions—such as user activity after logging into a website or application—can be grouped together and quickly analyzed\n",
    "* Session information can also be used to continuously update machine learning models\n",
    "* Companies such as Netflix use this functionality to gain immediate insights as to how users are engaging on their site and provide more real-time movie recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Other high level use cases\n",
    "* Twitter wants to process billions of tweets/s to publish trending topics\n",
    "* Credit card companies need to process millions of transactions for identifying fraud\n",
    "* Mobile applications like whatsapp need to constantly crunch logs for service availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Real Time Analytics\n",
    "* We need to process TB's of streaming data in real time to get up to date analysis\n",
    "* Data will be coming from more than one stream\n",
    "* Need to combine historical data with real time data\n",
    "* Ability to process stream data for downstream application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## There are alternatives to Spark\n",
    "* Apache Storm\n",
    "    * Stream processing built on HDFS\n",
    "    * Built by twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spark Streaming\n",
    "<img src=\"https://miro.medium.com/max/720/1*FLYjc6U-qAQ64yDLLrzdWw.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Micro batch\n",
    "* Spark streaming is a fast batch processing system\n",
    "* Collects stream data into small batches and processes them\n",
    "* Batch interval can be small (1s) or multiple hours\n",
    "* Batches are called DStreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The usual SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grab a streaming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PORT=9999 # Change this to a unique port before running individually\n",
    "HOST=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Run this command at the terminal and type in words and hit enter periodically:\")\n",
    "print(f\"nc -lk {PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(HOST, PORT)\n",
    "counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "              .map(lambda word: (word, 1))\\\n",
    "              .reduceByKey(lambda a, b: a+b)\n",
    "counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTerminationOrTimeout(60) # wait 60 seconds"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
