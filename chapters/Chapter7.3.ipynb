{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 7.3 - Spark Streaming\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ice Breaker\n",
    "\n",
    "Best breakfast burrito in town?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Statement:\n",
    "* You are approached by a company who has a machine learning pipeline that is trained and tested on historical data. \n",
    "* This pipeline is used by the company to sort tweets into one of three categories which also have a corresponding numerical label in parentheses.\n",
    "    * Negative (0)\n",
    "    * Positive (1)\n",
    "    * Neutral (2)\n",
    "    \n",
    "The company has heard about your amazing skills as a Spark streaming expert. They would like you to take their pre-trained classifier and update it with new incoming data processed via Spark streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Detours\n",
    "\n",
    "In order to implement our streaming approach, we need to take a couple of brief detours into machine learning. We need to answer the following questions:\n",
    "* How do we represent text as a vector of numbers such that a machine can mathematically learn from data?\n",
    "* How to use and evaluate an algorithm to predict numeric data into three categories (negative, positive, and neutral)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbTiSkqNb75B",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Representing text as a vector using `scikit-learn`\n",
    "\n",
    "scikit-learn is a popular package for machine learning.\n",
    "\n",
    "We will use a class called `CountVectorizer` in `scikit-learn` to obtain what is called the term-frequency matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A couple famous book openings:\n",
    "\n",
    "> The story so far: in the beginning, the universe was created. This has made a lot of people very angry and been widely regarded as a bad move - The Restaurant at the End of the Universe by Douglas Adams (1980)\n",
    "\n",
    "> Whether I shall turn out to be the hero of my own life, or whether that station will be held by anybody else, these pages must show. — Charles Dickens, David Copperfield (1850)\n",
    "\n",
    "How will a computer understand these sentences when computers can only add/mult/compare numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fhl2Kwb5b75C",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x46 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 48 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "famous_book_openings = [\n",
    "    \"The story so far: in the beginning, the universe was created. This has made a lot of people very angry and been widely regarded as a bad move\",\n",
    "    \"Whether I shall turn out to be the hero of my own life, or whether that station will be held by anybody else, these pages must show.\"\n",
    "]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit(famous_book_openings) # This determines the vocabulary.\n",
    "tf_sparse = vec.transform(famous_book_openings)\n",
    "tf_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Printing in a readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>angry</th>\n",
       "      <th>anybody</th>\n",
       "      <th>as</th>\n",
       "      <th>bad</th>\n",
       "      <th>be</th>\n",
       "      <th>been</th>\n",
       "      <th>beginning</th>\n",
       "      <th>by</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>these</th>\n",
       "      <th>this</th>\n",
       "      <th>to</th>\n",
       "      <th>turn</th>\n",
       "      <th>universe</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "      <th>whether</th>\n",
       "      <th>widely</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  angry  anybody  as  bad  be  been  beginning  by  created  ...  these  \\\n",
       "0    1      1        0   1    1   0     1          1   0        1  ...      0   \n",
       "1    0      0        1   0    0   2     0          0   1        0  ...      1   \n",
       "\n",
       "   this  to  turn  universe  very  was  whether  widely  will  \n",
       "0     1   0     0         1     1    1        0       1     0  \n",
       "1     0   1     1         0     0    0        2       0     1  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    tf_sparse.todense(),\n",
    "    columns=vec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Applying this process to our twitter data\n",
    "We will do the following:\n",
    "1. Load the tweets into a dataframe\n",
    "2. Convert those tweets into a term-frequency matrix using the code from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading tweets into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ItemID=9000, Sentiment=0, SentimentText='&quot;Gravity is not always convenient!&quot;-Mr. Donde lol I just dropped my phone  but I thought of this saying.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"ItemID\", IntegerType(), True), \\\n",
    "    StructField(\"Sentiment\", IntegerType(), True), \\\n",
    "    StructField(\"SentimentText\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "spark_df = spark.read.schema(schema).csv(f'{home}/csc-369-student/data/twitter_sentiment_analysis/historical/xa*')\n",
    "spark_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convert to Pandas DataFrame for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;Gravity is not always convenient!&amp;quot;-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9001</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;quot;Ha-ha!&amp;quot; to the premature PSP Go! re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9002</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;Hahah your just jealous your not as thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9003</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot; lesbian, gay and bisexual students are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9004</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;quot; mileycyrus i wanna perform with lady ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0    9000          0  &quot;Gravity is not always convenient!&quot;-...\n",
       "1    9001          1  &quot;Ha-ha!&quot; to the premature PSP Go! re...\n",
       "2    9002          0  &quot;Hahah your just jealous your not as thin...\n",
       "3    9003          0  &quot; lesbian, gay and bisexual students are ...\n",
       "4    9004          1  &quot; mileycyrus i wanna perform with lady ga..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_training_data = spark_df.toPandas()\n",
    "historical_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convert to a term frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit(historical_training_data['SentimentText']) # This determines the vocabulary.\n",
    "tf_sparse = vec.transform(historical_training_data['SentimentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mathematical model for prediction\n",
    "* We will use a multinomial Bayes classifier. \n",
    "* It is a statistical classifier that has good baseline performance for text analysis. \n",
    "* It's a classifier that you can update as new data arrives (i.e., online learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(tf_sparse,historical_training_data['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**How well does this model predict on historical data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new historical test data: 0.7223846153846154\n"
     ]
    }
   ],
   "source": [
    "test_spark_df = spark.read.schema(schema).csv(f'{home}/csc-369-student/data/twitter_sentiment_analysis/historical/xb*')\n",
    "historical_test_data = test_spark_df.toPandas()\n",
    "test_tf_sparse = vec.transform(historical_test_data['SentimentText'])\n",
    "print(\"Accuracy on new historical test data:\",sum(model.predict(test_tf_sparse) == historical_test_data['Sentiment'])/len(historical_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**We've got a predictive model that does better than guessing!**\n",
    "\n",
    "That's enough for this illustrative example. Now how would we update this using Spark Streaming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The usual SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grab a streaming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create a directory where we can add tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_dir=\"/tmp/tweets\"\n",
    "!rm -rf {data_dir}\n",
    "!mkdir {data_dir}\n",
    "!chmod 777 {data_dir}\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Code from 7.2\n",
    "\n",
    "```python\n",
    "data_dir = \"/tmp/add_books_here\"\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import traceback\n",
    "\n",
    "# Lazily instantiated global instance of SparkSession\n",
    "def getSparkSessionInstance(sparkConf):\n",
    "    if (\"sparkSessionSingletonInstance\" not in globals()):\n",
    "        globals()[\"sparkSessionSingletonInstance\"] = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(conf=sparkConf) \\\n",
    "            .getOrCreate()\n",
    "    return globals()[\"sparkSessionSingletonInstance\"]\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "ssc.checkpoint(\"checkpoint\")\n",
    "\n",
    "lines = ssc.textFileStream(data_dir)\n",
    "\n",
    "def process(time, rdd):\n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    # Get the singleton instance of SparkSession\n",
    "    try:\n",
    "        spark = getSparkSessionInstance(rdd.context.getConf())\n",
    "        # Convert RDD[String] to RDD[Row] to DataFrame\n",
    "        words = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: word)\n",
    "        rowRdd = words.map(lambda w: Row(word=w))\n",
    "        wordsDataFrame = spark.createDataFrame(rowRdd)\n",
    "\n",
    "        # Creates a temporary view using the DataFrame\n",
    "        wordsDataFrame.createOrReplaceTempView(\"words\")\n",
    "\n",
    "        # Do word count on table using SQL and print it\n",
    "        wordCountsDataFrame = spark.sql(\"select word, count(*) as total from words group by word\")\n",
    "        print(wordCountsDataFrame.show())\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "lines.foreachRDD(process)\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(30)\n",
    "#ssc.awaitTerminationOrTimeout(60) # wait 60 seconds\n",
    "ssc.stop(stopSparkContext=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How would you modify this so it updates the model via Spark Streaming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2021-11-04 21:24:49 =========\n",
      "========= 2021-11-04 21:24:50 =========\n",
      "========= 2021-11-04 21:24:51 =========\n",
      "MultinomialNB()\n",
      "========= 2021-11-04 21:24:52 =========\n",
      "========= 2021-11-04 21:24:53 =========\n",
      "========= 2021-11-04 21:24:54 =========\n",
      "========= 2021-11-04 21:24:55 =========\n",
      "========= 2021-11-04 21:24:56 =========\n",
      "========= 2021-11-04 21:24:57 =========\n",
      "========= 2021-11-04 21:24:58 =========\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "\n",
    "ssc.start()\n",
    "import time; time.sleep(10)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Help our algorithm by copying some of the data files in the directory!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xca  xce  xci  xcm  xcq  xcu  xcy  xdc\txdg  xdk  xdo  xds  xdw\n",
      "xcb  xcf  xcj  xcn  xcr  xcv  xcz  xdd\txdh  xdl  xdp  xdt\n",
      "xcc  xcg  xck  xco  xcs  xcw  xda  xde\txdi  xdm  xdq  xdu\n",
      "xcd  xch  xcl  xcp  xct  xcx  xdb  xdf\txdj  xdn  xdr  xdv\n"
     ]
    }
   ],
   "source": [
    "!ls {home}/csc-369-student/data/twitter_sentiment_analysis/streaming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp ~/csc-369-student/data/twitter_sentiment_analysis/streaming/xca /tmp/tweets\r\n"
     ]
    }
   ],
   "source": [
    "!echo cp \\~/csc-369-student/data/twitter_sentiment_analysis/streaming/xca {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**When we are ready we can check the accuracy again. In theory, we should get better with more data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new historical test data: 0.7566538461538461\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on new historical test data:\",sum(model.predict(test_tf_sparse) == historical_test_data['Sentiment'])/len(historical_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thank you! Don't forget to push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
