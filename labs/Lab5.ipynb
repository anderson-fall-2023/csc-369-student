{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 5 - Spark Lab 2\n",
    "\n",
    "## Map/Reduce\n",
    "\n",
    "In this lab you will implement matrix multiplication using Spark with two different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Put all your solutions into Lab1_helper.py as this script which is autograded\n",
    "import Lab5_helper\n",
    "    \n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 1:**\n",
    "Using the Spark functions (cartesian, map, collect), and the numpy function (np.dot or a loop of your own), compute the matrix multiplication of A_RDD and B_RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_RDD = sc.parallelize(Lab5_helper.A1)\n",
    "B1_RDD = sc.parallelize(Lab5_helper.B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 58), ((1, 2), 64), ((2, 1), 139), ((2, 2), 154)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Lab5_helper.exercise_1(A1_RDD,B1_RDD)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 2:** Implement matrix multiplication using the following alternative format:\n",
    "\n",
    "'row number', 'column number', 'value'\n",
    "\n",
    "For this exercise, you cannot use loops or np.dot. It should be Spark centric using cartesian, join, map, add, reduceByKey, and/or collect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_RDD = sc.parallelize(Lab5_helper.A2)\n",
    "B2_RDD = sc.parallelize(Lab5_helper.B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 2), 144),\n",
       " ((3, 1), 0),\n",
       " ((3, 3), 0),\n",
       " ((2, 3), 27),\n",
       " ((2, 2), 68),\n",
       " ((4, 3), 63),\n",
       " ((1, 2), 8),\n",
       " ((1, 3), 9),\n",
       " ((3, 2), 66),\n",
       " ((1, 1), 7),\n",
       " ((4, 1), 49),\n",
       " ((2, 1), 21)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Lab5_helper.exercise_2(A2_RDD,B2_RDD)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 3:** Implement matrix multiplication using the following alternative format that assumes missing rows have a value of 0 (i.e., sparse matrices):\n",
    "\n",
    "'row number', 'column number', 'value'\n",
    "\n",
    "For this exercise, you cannot use loops or np.dot. It should be Spark centric using join, map, add, reduceByKey, and/or collect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3_RDD = sc.parallelize(Lab5_helper.A3)\n",
    "B3_RDD = sc.parallelize(Lab5_helper.B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 2), 144),\n",
       " ((2, 3), 27),\n",
       " ((2, 2), 68),\n",
       " ((4, 3), 63),\n",
       " ((1, 2), 8),\n",
       " ((1, 3), 9),\n",
       " ((3, 2), 66),\n",
       " ((1, 1), 7),\n",
       " ((4, 1), 49),\n",
       " ((2, 1), 21)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Lab5_helper.exercise_3(A3_RDD,B3_RDD)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't forget to push!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
